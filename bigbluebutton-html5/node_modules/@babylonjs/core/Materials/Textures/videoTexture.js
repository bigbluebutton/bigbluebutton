import { __extends } from "tslib";
import { Observable } from "../../Misc/observable";
import { Tools } from "../../Misc/tools";
import { Logger } from "../../Misc/logger";
import { Texture } from "../../Materials/Textures/texture";
import "../../Engines/Extensions/engine.videoTexture";
/**
 * If you want to display a video in your scene, this is the special texture for that.
 * This special texture works similar to other textures, with the exception of a few parameters.
 * @see https://doc.babylonjs.com/how_to/video_texture
 */
var VideoTexture = /** @class */ (function (_super) {
    __extends(VideoTexture, _super);
    /**
     * Creates a video texture.
     * If you want to display a video in your scene, this is the special texture for that.
     * This special texture works similar to other textures, with the exception of a few parameters.
     * @see https://doc.babylonjs.com/how_to/video_texture
     * @param name optional name, will detect from video source, if not defined
     * @param src can be used to provide an url, array of urls or an already setup HTML video element.
     * @param scene is obviously the current scene.
     * @param generateMipMaps can be used to turn on mipmaps (Can be expensive for videoTextures because they are often updated).
     * @param invertY is false by default but can be used to invert video on Y axis
     * @param samplingMode controls the sampling method and is set to TRILINEAR_SAMPLINGMODE by default
     * @param settings allows finer control over video usage
     */
    function VideoTexture(name, src, scene, generateMipMaps, invertY, samplingMode, settings) {
        if (generateMipMaps === void 0) { generateMipMaps = false; }
        if (invertY === void 0) { invertY = false; }
        if (samplingMode === void 0) { samplingMode = Texture.TRILINEAR_SAMPLINGMODE; }
        if (settings === void 0) { settings = {
            autoPlay: true,
            loop: true,
            autoUpdateTexture: true,
        }; }
        var _this = _super.call(this, null, scene, !generateMipMaps, invertY) || this;
        _this._onUserActionRequestedObservable = null;
        _this._stillImageCaptured = false;
        _this._displayingPosterTexture = false;
        _this._frameId = -1;
        _this._currentSrc = null;
        _this._createInternalTexture = function () {
            if (_this._texture != null) {
                if (_this._displayingPosterTexture) {
                    _this._texture.dispose();
                    _this._displayingPosterTexture = false;
                }
                else {
                    return;
                }
            }
            if (!_this._engine.needPOTTextures ||
                (Tools.IsExponentOfTwo(_this.video.videoWidth) && Tools.IsExponentOfTwo(_this.video.videoHeight))) {
                _this.wrapU = Texture.WRAP_ADDRESSMODE;
                _this.wrapV = Texture.WRAP_ADDRESSMODE;
            }
            else {
                _this.wrapU = Texture.CLAMP_ADDRESSMODE;
                _this.wrapV = Texture.CLAMP_ADDRESSMODE;
                _this._generateMipMaps = false;
            }
            _this._texture = _this._engine.createDynamicTexture(_this.video.videoWidth, _this.video.videoHeight, _this._generateMipMaps, _this.samplingMode);
            if (!_this.video.autoplay && !_this._settings.poster) {
                var oldHandler_1 = _this.video.onplaying;
                var error_1 = false;
                var oldMuted_1 = _this.video.muted;
                _this.video.muted = true;
                _this.video.onplaying = function () {
                    _this.video.muted = oldMuted_1;
                    _this.video.onplaying = oldHandler_1;
                    _this._texture.isReady = true;
                    _this._updateInternalTexture();
                    if (!error_1) {
                        _this.video.pause();
                    }
                    if (_this.onLoadObservable.hasObservers()) {
                        _this.onLoadObservable.notifyObservers(_this);
                    }
                };
                var playing = _this.video.play();
                if (playing) {
                    playing.then(function () {
                        // Everything is good.
                    })
                        .catch(function () {
                        error_1 = true;
                        // On Chrome for instance, new policies might prevent playing without user interaction.
                        if (_this._onUserActionRequestedObservable && _this._onUserActionRequestedObservable.hasObservers()) {
                            _this._onUserActionRequestedObservable.notifyObservers(_this);
                        }
                    });
                }
                else {
                    _this.video.onplaying = oldHandler_1;
                    _this._texture.isReady = true;
                    _this._updateInternalTexture();
                    if (_this.onLoadObservable.hasObservers()) {
                        _this.onLoadObservable.notifyObservers(_this);
                    }
                }
            }
            else {
                _this._texture.isReady = true;
                _this._updateInternalTexture();
                if (_this.onLoadObservable.hasObservers()) {
                    _this.onLoadObservable.notifyObservers(_this);
                }
            }
        };
        _this.reset = function () {
            if (_this._texture == null) {
                return;
            }
            if (!_this._displayingPosterTexture) {
                _this._texture.dispose();
                _this._texture = null;
            }
        };
        _this._updateInternalTexture = function () {
            if (_this._texture == null || !_this._texture.isReady) {
                return;
            }
            if (_this.video.readyState < _this.video.HAVE_CURRENT_DATA) {
                return;
            }
            if (_this._displayingPosterTexture) {
                return;
            }
            var frameId = _this.getScene().getFrameId();
            if (_this._frameId === frameId) {
                return;
            }
            _this._frameId = frameId;
            _this._engine.updateVideoTexture(_this._texture, _this.video, _this._invertY);
        };
        _this._engine = _this.getScene().getEngine();
        _this._generateMipMaps = generateMipMaps;
        _this._initialSamplingMode = samplingMode;
        _this.autoUpdateTexture = settings.autoUpdateTexture;
        _this._currentSrc = src;
        _this.name = name || _this._getName(src);
        _this.video = _this._getVideo(src);
        _this._settings = settings;
        if (settings.poster) {
            _this.video.poster = settings.poster;
        }
        if (settings.autoPlay !== undefined) {
            _this.video.autoplay = settings.autoPlay;
        }
        if (settings.loop !== undefined) {
            _this.video.loop = settings.loop;
        }
        _this.video.setAttribute("playsinline", "");
        _this.video.addEventListener("paused", _this._updateInternalTexture);
        _this.video.addEventListener("seeked", _this._updateInternalTexture);
        _this.video.addEventListener("emptied", _this.reset);
        _this._createInternalTextureOnEvent = (settings.poster && !settings.autoPlay) ? "play" : "canplay";
        _this.video.addEventListener(_this._createInternalTextureOnEvent, _this._createInternalTexture);
        var videoHasEnoughData = (_this.video.readyState >= _this.video.HAVE_CURRENT_DATA);
        if (settings.poster &&
            (!settings.autoPlay || !videoHasEnoughData)) {
            _this._texture = _this._engine.createTexture(settings.poster, false, !_this.invertY, scene);
            _this._displayingPosterTexture = true;
        }
        else if (videoHasEnoughData) {
            _this._createInternalTexture();
        }
        return _this;
    }
    Object.defineProperty(VideoTexture.prototype, "onUserActionRequestedObservable", {
        /**
         * Event triggerd when a dom action is required by the user to play the video.
         * This happens due to recent changes in browser policies preventing video to auto start.
         */
        get: function () {
            if (!this._onUserActionRequestedObservable) {
                this._onUserActionRequestedObservable = new Observable();
            }
            return this._onUserActionRequestedObservable;
        },
        enumerable: true,
        configurable: true
    });
    VideoTexture.prototype._getName = function (src) {
        if (src instanceof HTMLVideoElement) {
            return src.currentSrc;
        }
        if (typeof src === "object") {
            return src.toString();
        }
        return src;
    };
    VideoTexture.prototype._getVideo = function (src) {
        if (src instanceof HTMLVideoElement) {
            Tools.SetCorsBehavior(src.currentSrc, src);
            return src;
        }
        var video = document.createElement("video");
        if (typeof src === "string") {
            Tools.SetCorsBehavior(src, video);
            video.src = src;
        }
        else {
            Tools.SetCorsBehavior(src[0], video);
            src.forEach(function (url) {
                var source = document.createElement("source");
                source.src = url;
                video.appendChild(source);
            });
        }
        return video;
    };
    /**
     * @hidden Internal method to initiate `update`.
     */
    VideoTexture.prototype._rebuild = function () {
        this.update();
    };
    /**
     * Update Texture in the `auto` mode. Does not do anything if `settings.autoUpdateTexture` is false.
     */
    VideoTexture.prototype.update = function () {
        if (!this.autoUpdateTexture) {
            // Expecting user to call `updateTexture` manually
            return;
        }
        this.updateTexture(true);
    };
    /**
     * Update Texture in `manual` mode. Does not do anything if not visible or paused.
     * @param isVisible Visibility state, detected by user using `scene.getActiveMeshes()` or othervise.
     */
    VideoTexture.prototype.updateTexture = function (isVisible) {
        if (!isVisible) {
            return;
        }
        if (this.video.paused && this._stillImageCaptured) {
            return;
        }
        this._stillImageCaptured = true;
        this._updateInternalTexture();
    };
    /**
     * Change video content. Changing video instance or setting multiple urls (as in constructor) is not supported.
     * @param url New url.
     */
    VideoTexture.prototype.updateURL = function (url) {
        this.video.src = url;
        this._currentSrc = url;
    };
    /**
     * Clones the texture.
     * @returns the cloned texture
     */
    VideoTexture.prototype.clone = function () {
        return new VideoTexture(this.name, this._currentSrc, this.getScene(), this._generateMipMaps, this.invertY, this.samplingMode, this._settings);
    };
    /**
     * Dispose the texture and release its associated resources.
     */
    VideoTexture.prototype.dispose = function () {
        _super.prototype.dispose.call(this);
        this._currentSrc = null;
        if (this._onUserActionRequestedObservable) {
            this._onUserActionRequestedObservable.clear();
            this._onUserActionRequestedObservable = null;
        }
        this.video.removeEventListener(this._createInternalTextureOnEvent, this._createInternalTexture);
        this.video.removeEventListener("paused", this._updateInternalTexture);
        this.video.removeEventListener("seeked", this._updateInternalTexture);
        this.video.removeEventListener("emptied", this.reset);
        this.video.pause();
    };
    /**
     * Creates a video texture straight from a stream.
     * @param scene Define the scene the texture should be created in
     * @param stream Define the stream the texture should be created from
     * @returns The created video texture as a promise
     */
    VideoTexture.CreateFromStreamAsync = function (scene, stream) {
        var video = document.createElement("video");
        video.setAttribute('autoplay', '');
        video.setAttribute('muted', 'true');
        video.setAttribute('playsinline', '');
        video.muted = true;
        if (video.mozSrcObject !== undefined) {
            // hack for Firefox < 19
            video.mozSrcObject = stream;
        }
        else {
            if (typeof video.srcObject == "object") {
                video.srcObject = stream;
            }
            else {
                window.URL = window.URL || window.webkitURL || window.mozURL || window.msURL;
                video.src = (window.URL && window.URL.createObjectURL(stream));
            }
        }
        return new Promise(function (resolve) {
            var onPlaying = function () {
                resolve(new VideoTexture("video", video, scene, true, true));
                video.removeEventListener("playing", onPlaying);
            };
            video.addEventListener("playing", onPlaying);
            video.play();
        });
    };
    /**
     * Creates a video texture straight from your WebCam video feed.
     * @param scene Define the scene the texture should be created in
     * @param constraints Define the constraints to use to create the web cam feed from WebRTC
     * @param audioConstaints Define the audio constraints to use to create the web cam feed from WebRTC
     * @returns The created video texture as a promise
     */
    VideoTexture.CreateFromWebCamAsync = function (scene, constraints, audioConstaints) {
        var _this = this;
        if (audioConstaints === void 0) { audioConstaints = false; }
        var constraintsDeviceId;
        if (constraints && constraints.deviceId) {
            constraintsDeviceId = {
                exact: constraints.deviceId,
            };
        }
        if (navigator.mediaDevices) {
            return navigator.mediaDevices.getUserMedia({
                video: constraints,
                audio: audioConstaints
            })
                .then(function (stream) {
                return _this.CreateFromStreamAsync(scene, stream);
            });
        }
        else {
            navigator.getUserMedia =
                navigator.getUserMedia ||
                    navigator.webkitGetUserMedia ||
                    navigator.mozGetUserMedia ||
                    navigator.msGetUserMedia;
            if (navigator.getUserMedia) {
                navigator.getUserMedia({
                    video: {
                        deviceId: constraintsDeviceId,
                        width: {
                            min: (constraints && constraints.minWidth) || 256,
                            max: (constraints && constraints.maxWidth) || 640,
                        },
                        height: {
                            min: (constraints && constraints.minHeight) || 256,
                            max: (constraints && constraints.maxHeight) || 480,
                        },
                    },
                    audio: audioConstaints
                }, function (stream) {
                    return _this.CreateFromStreamAsync(scene, stream);
                }, function (e) {
                    Logger.Error(e.name);
                });
            }
        }
        return Promise.reject("No support for userMedia on this device");
    };
    /**
     * Creates a video texture straight from your WebCam video feed.
     * @param scene Define the scene the texture should be created in
     * @param onReady Define a callback to triggered once the texture will be ready
     * @param constraints Define the constraints to use to create the web cam feed from WebRTC
     * @param audioConstaints Define the audio constraints to use to create the web cam feed from WebRTC
     */
    VideoTexture.CreateFromWebCam = function (scene, onReady, constraints, audioConstaints) {
        if (audioConstaints === void 0) { audioConstaints = false; }
        this.CreateFromWebCamAsync(scene, constraints, audioConstaints)
            .then(function (videoTexture) {
            if (onReady) {
                onReady(videoTexture);
            }
        })
            .catch(function (err) {
            Logger.Error(err.name);
        });
    };
    return VideoTexture;
}(Texture));
export { VideoTexture };
//# sourceMappingURL=videoTexture.js.map