import { __decorate, __extends } from "tslib";
import { serialize, serializeAsTexture, SerializationHelper } from "../../../Misc/decorators";
import { Logger } from "../../../Misc/logger";
import { Vector2, Vector3, Matrix, Vector4 } from "../../../Maths/math.vector";
import { Scalar } from "../../../Maths/math.scalar";
import { Texture } from "../../../Materials/Textures/texture";
import { PostProcess } from "../../../PostProcesses/postProcess";
import { PostProcessRenderPipeline } from "../../../PostProcesses/RenderPipeline/postProcessRenderPipeline";
import { PostProcessRenderEffect } from "../../../PostProcesses/RenderPipeline/postProcessRenderEffect";
import { BlurPostProcess } from "../../../PostProcesses/blurPostProcess";
import { FxaaPostProcess } from "../../../PostProcesses/fxaaPostProcess";
import { _TypeStore } from '../../../Misc/typeStore';
import { MotionBlurPostProcess } from "../../motionBlurPostProcess";
import { ScreenSpaceReflectionPostProcess } from "../../screenSpaceReflectionPostProcess";
import "../../../PostProcesses/RenderPipeline/postProcessRenderPipelineManagerSceneComponent";
import "../../../Shaders/standard.fragment";
/**
 * Standard rendering pipeline
 * Default pipeline should be used going forward but the standard pipeline will be kept for backwards compatibility.
 * @see https://doc.babylonjs.com/how_to/using_standard_rendering_pipeline
 */
var StandardRenderingPipeline = /** @class */ (function (_super) {
    __extends(StandardRenderingPipeline, _super);
    /**
     * Default pipeline should be used going forward but the standard pipeline will be kept for backwards compatibility.
     * @constructor
     * @param name The rendering pipeline name
     * @param scene The scene linked to this pipeline
     * @param ratio The size of the postprocesses (0.5 means that your postprocess will have a width = canvas.width 0.5 and a height = canvas.height 0.5)
     * @param originalPostProcess the custom original color post-process. Must be "reusable". Can be null.
     * @param cameras The array of cameras that the rendering pipeline will be attached to
     */
    function StandardRenderingPipeline(name, scene, ratio, originalPostProcess, cameras) {
        if (originalPostProcess === void 0) { originalPostProcess = null; }
        var _this = _super.call(this, scene.getEngine(), name) || this;
        /**
         * Post-process used to down scale an image x4
         */
        _this.downSampleX4PostProcess = null;
        /**
         * Post-process used to calculate the illuminated surfaces controlled by a threshold
         */
        _this.brightPassPostProcess = null;
        /**
         * Post-process array storing all the horizontal blur post-processes used by the pipeline
         */
        _this.blurHPostProcesses = [];
        /**
         * Post-process array storing all the vertical blur post-processes used by the pipeline
         */
        _this.blurVPostProcesses = [];
        /**
         * Post-process used to add colors of 2 textures (typically brightness + real scene color)
         */
        _this.textureAdderPostProcess = null;
        /**
         * Post-process used to create volumetric lighting effect
         */
        _this.volumetricLightPostProcess = null;
        /**
         * Post-process used to smooth the previous volumetric light post-process on the X axis
         */
        _this.volumetricLightSmoothXPostProcess = null;
        /**
         * Post-process used to smooth the previous volumetric light post-process on the Y axis
         */
        _this.volumetricLightSmoothYPostProcess = null;
        /**
         * Post-process used to merge the volumetric light effect and the real scene color
         */
        _this.volumetricLightMergePostProces = null;
        /**
         * Post-process used to store the final volumetric light post-process (attach/detach for debug purpose)
         */
        _this.volumetricLightFinalPostProcess = null;
        /**
         * Base post-process used to calculate the average luminance of the final image for HDR
         */
        _this.luminancePostProcess = null;
        /**
         * Post-processes used to create down sample post-processes in order to get
         * the average luminance of the final image for HDR
         * Array of length "StandardRenderingPipeline.LuminanceSteps"
         */
        _this.luminanceDownSamplePostProcesses = [];
        /**
         * Post-process used to create a HDR effect (light adaptation)
         */
        _this.hdrPostProcess = null;
        /**
         * Post-process used to store the final texture adder post-process (attach/detach for debug purpose)
         */
        _this.textureAdderFinalPostProcess = null;
        /**
         * Post-process used to store the final lens flare post-process (attach/detach for debug purpose)
         */
        _this.lensFlareFinalPostProcess = null;
        /**
         * Post-process used to merge the final HDR post-process and the real scene color
         */
        _this.hdrFinalPostProcess = null;
        /**
         * Post-process used to create a lens flare effect
         */
        _this.lensFlarePostProcess = null;
        /**
         * Post-process that merges the result of the lens flare post-process and the real scene color
         */
        _this.lensFlareComposePostProcess = null;
        /**
         * Post-process used to create a motion blur effect
         */
        _this.motionBlurPostProcess = null;
        /**
         * Post-process used to create a depth of field effect
         */
        _this.depthOfFieldPostProcess = null;
        /**
         * The Fast Approximate Anti-Aliasing post process which attemps to remove aliasing from an image.
         */
        _this.fxaaPostProcess = null;
        /**
         * Post-process used to simulate realtime reflections using the screen space and geometry renderer.
         */
        _this.screenSpaceReflectionPostProcess = null;
        // Values
        /**
         * Represents the brightness threshold in order to configure the illuminated surfaces
         */
        _this.brightThreshold = 1.0;
        /**
         * Configures the blur intensity used for surexposed surfaces are highlighted surfaces (light halo)
         */
        _this.blurWidth = 512.0;
        /**
         * Sets if the blur for highlighted surfaces must be only horizontal
         */
        _this.horizontalBlur = false;
        /**
         * Texture used typically to simulate "dirty" on camera lens
         */
        _this.lensTexture = null;
        /**
         * Represents the offset coefficient based on Rayleigh principle. Typically in interval [-0.2, 0.2]
         */
        _this.volumetricLightCoefficient = 0.2;
        /**
         * The overall power of volumetric lights, typically in interval [0, 10] maximum
         */
        _this.volumetricLightPower = 4.0;
        /**
         * Used the set the blur intensity to smooth the volumetric lights
         */
        _this.volumetricLightBlurScale = 64.0;
        /**
         * Light (spot or directional) used to generate the volumetric lights rays
         * The source light must have a shadow generate so the pipeline can get its
         * depth map
         */
        _this.sourceLight = null;
        /**
         * For eye adaptation, represents the minimum luminance the eye can see
         */
        _this.hdrMinimumLuminance = 1.0;
        /**
         * For eye adaptation, represents the decrease luminance speed
         */
        _this.hdrDecreaseRate = 0.5;
        /**
         * For eye adaptation, represents the increase luminance speed
         */
        _this.hdrIncreaseRate = 0.5;
        /**
         * Lens color texture used by the lens flare effect. Mandatory if lens flare effect enabled
         */
        _this.lensColorTexture = null;
        /**
         * The overall strengh for the lens flare effect
         */
        _this.lensFlareStrength = 20.0;
        /**
         * Dispersion coefficient for lens flare ghosts
         */
        _this.lensFlareGhostDispersal = 1.4;
        /**
         * Main lens flare halo width
         */
        _this.lensFlareHaloWidth = 0.7;
        /**
         * Based on the lens distortion effect, defines how much the lens flare result
         * is distorted
         */
        _this.lensFlareDistortionStrength = 16.0;
        /**
         * Configures the blur intensity used for for lens flare (halo)
         */
        _this.lensFlareBlurWidth = 512.0;
        /**
         * Lens star texture must be used to simulate rays on the flares and is available
         * in the documentation
         */
        _this.lensStarTexture = null;
        /**
         * As the "lensTexture" (can be the same texture or different), it is used to apply the lens
         * flare effect by taking account of the dirt texture
         */
        _this.lensFlareDirtTexture = null;
        /**
         * Represents the focal length for the depth of field effect
         */
        _this.depthOfFieldDistance = 10.0;
        /**
         * Represents the blur intensity for the blurred part of the depth of field effect
         */
        _this.depthOfFieldBlurWidth = 64.0;
        /**
         * List of animations for the pipeline (IAnimatable implementation)
         */
        _this.animations = [];
        _this._currentDepthOfFieldSource = null;
        _this._fixedExposure = 1.0;
        _this._currentExposure = 1.0;
        _this._hdrAutoExposure = false;
        _this._hdrCurrentLuminance = 1.0;
        _this._motionStrength = 1.0;
        _this._isObjectBasedMotionBlur = false;
        _this._camerasToBeAttached = [];
        // Getters and setters
        _this._bloomEnabled = false;
        _this._depthOfFieldEnabled = false;
        _this._vlsEnabled = false;
        _this._lensFlareEnabled = false;
        _this._hdrEnabled = false;
        _this._motionBlurEnabled = false;
        _this._fxaaEnabled = false;
        _this._screenSpaceReflectionsEnabled = false;
        _this._motionBlurSamples = 64.0;
        _this._volumetricLightStepsCount = 50.0;
        _this._samples = 1;
        _this._cameras = cameras || scene.cameras;
        _this._cameras = _this._cameras.slice();
        _this._camerasToBeAttached = _this._cameras.slice();
        // Initialize
        _this._scene = scene;
        _this._basePostProcess = originalPostProcess;
        _this._ratio = ratio;
        // Misc
        _this._floatTextureType = scene.getEngine().getCaps().textureFloatRender ? 1 : 2;
        // Finish
        scene.postProcessRenderPipelineManager.addPipeline(_this);
        _this._buildPipeline();
        return _this;
    }
    Object.defineProperty(StandardRenderingPipeline.prototype, "exposure", {
        /**
         * Gets the overall exposure used by the pipeline
         */
        get: function () {
            return this._fixedExposure;
        },
        /**
         * Sets the overall exposure used by the pipeline
         */
        set: function (value) {
            this._fixedExposure = value;
            this._currentExposure = value;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(StandardRenderingPipeline.prototype, "hdrAutoExposure", {
        /**
         * Gets wether or not the exposure of the overall pipeline should be automatically adjusted by the HDR post-process
         */
        get: function () {
            return this._hdrAutoExposure;
        },
        /**
         * Sets wether or not the exposure of the overall pipeline should be automatically adjusted by the HDR post-process
         */
        set: function (value) {
            this._hdrAutoExposure = value;
            if (this.hdrPostProcess) {
                var defines = ["#define HDR"];
                if (value) {
                    defines.push("#define AUTO_EXPOSURE");
                }
                this.hdrPostProcess.updateEffect(defines.join("\n"));
            }
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(StandardRenderingPipeline.prototype, "motionStrength", {
        /**
         * Gets how much the image is blurred by the movement while using the motion blur post-process
         */
        get: function () {
            return this._motionStrength;
        },
        /**
         * Sets how much the image is blurred by the movement while using the motion blur post-process
         */
        set: function (strength) {
            this._motionStrength = strength;
            if (this._isObjectBasedMotionBlur && this.motionBlurPostProcess) {
                this.motionBlurPostProcess.motionStrength = strength;
            }
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(StandardRenderingPipeline.prototype, "objectBasedMotionBlur", {
        /**
         * Gets wether or not the motion blur post-process is object based or screen based.
         */
        get: function () {
            return this._isObjectBasedMotionBlur;
        },
        /**
         * Sets wether or not the motion blur post-process should be object based or screen based
         */
        set: function (value) {
            var shouldRebuild = this._isObjectBasedMotionBlur !== value;
            this._isObjectBasedMotionBlur = value;
            if (shouldRebuild) {
                this._buildPipeline();
            }
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(StandardRenderingPipeline.prototype, "BloomEnabled", {
        /**
         * @ignore
         * Specifies if the bloom pipeline is enabled
         */
        get: function () {
            return this._bloomEnabled;
        },
        set: function (enabled) {
            if (this._bloomEnabled === enabled) {
                return;
            }
            this._bloomEnabled = enabled;
            this._buildPipeline();
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(StandardRenderingPipeline.prototype, "DepthOfFieldEnabled", {
        /**
         * @ignore
         * Specifies if the depth of field pipeline is enabed
         */
        get: function () {
            return this._depthOfFieldEnabled;
        },
        set: function (enabled) {
            if (this._depthOfFieldEnabled === enabled) {
                return;
            }
            this._depthOfFieldEnabled = enabled;
            this._buildPipeline();
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(StandardRenderingPipeline.prototype, "LensFlareEnabled", {
        /**
         * @ignore
         * Specifies if the lens flare pipeline is enabed
         */
        get: function () {
            return this._lensFlareEnabled;
        },
        set: function (enabled) {
            if (this._lensFlareEnabled === enabled) {
                return;
            }
            this._lensFlareEnabled = enabled;
            this._buildPipeline();
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(StandardRenderingPipeline.prototype, "HDREnabled", {
        /**
         * @ignore
         * Specifies if the HDR pipeline is enabled
         */
        get: function () {
            return this._hdrEnabled;
        },
        set: function (enabled) {
            if (this._hdrEnabled === enabled) {
                return;
            }
            this._hdrEnabled = enabled;
            this._buildPipeline();
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(StandardRenderingPipeline.prototype, "VLSEnabled", {
        /**
         * @ignore
         * Specifies if the volumetric lights scattering effect is enabled
         */
        get: function () {
            return this._vlsEnabled;
        },
        set: function (enabled) {
            if (this._vlsEnabled === enabled) {
                return;
            }
            if (enabled) {
                var geometry = this._scene.enableGeometryBufferRenderer();
                if (!geometry) {
                    Logger.Warn("Geometry renderer is not supported, cannot create volumetric lights in Standard Rendering Pipeline");
                    return;
                }
            }
            this._vlsEnabled = enabled;
            this._buildPipeline();
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(StandardRenderingPipeline.prototype, "MotionBlurEnabled", {
        /**
         * @ignore
         * Specifies if the motion blur effect is enabled
         */
        get: function () {
            return this._motionBlurEnabled;
        },
        set: function (enabled) {
            if (this._motionBlurEnabled === enabled) {
                return;
            }
            this._motionBlurEnabled = enabled;
            this._buildPipeline();
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(StandardRenderingPipeline.prototype, "fxaaEnabled", {
        /**
         * Specifies if anti-aliasing is enabled
         */
        get: function () {
            return this._fxaaEnabled;
        },
        set: function (enabled) {
            if (this._fxaaEnabled === enabled) {
                return;
            }
            this._fxaaEnabled = enabled;
            this._buildPipeline();
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(StandardRenderingPipeline.prototype, "screenSpaceReflectionsEnabled", {
        /**
         * Specifies if screen space reflections are enabled.
         */
        get: function () {
            return this._screenSpaceReflectionsEnabled;
        },
        set: function (enabled) {
            if (this._screenSpaceReflectionsEnabled === enabled) {
                return;
            }
            this._screenSpaceReflectionsEnabled = enabled;
            this._buildPipeline();
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(StandardRenderingPipeline.prototype, "volumetricLightStepsCount", {
        /**
         * Specifies the number of steps used to calculate the volumetric lights
         * Typically in interval [50, 200]
         */
        get: function () {
            return this._volumetricLightStepsCount;
        },
        set: function (count) {
            if (this.volumetricLightPostProcess) {
                this.volumetricLightPostProcess.updateEffect("#define VLS\n#define NB_STEPS " + count.toFixed(1));
            }
            this._volumetricLightStepsCount = count;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(StandardRenderingPipeline.prototype, "motionBlurSamples", {
        /**
         * Specifies the number of samples used for the motion blur effect
         * Typically in interval [16, 64]
         */
        get: function () {
            return this._motionBlurSamples;
        },
        set: function (samples) {
            if (this.motionBlurPostProcess) {
                if (this._isObjectBasedMotionBlur) {
                    this.motionBlurPostProcess.motionBlurSamples = samples;
                }
                else {
                    this.motionBlurPostProcess.updateEffect("#define MOTION_BLUR\n#define MAX_MOTION_SAMPLES " + samples.toFixed(1));
                }
            }
            this._motionBlurSamples = samples;
        },
        enumerable: true,
        configurable: true
    });
    Object.defineProperty(StandardRenderingPipeline.prototype, "samples", {
        /**
         * Specifies MSAA sample count, setting this to 4 will provide 4x anti aliasing. (default: 1)
         */
        get: function () {
            return this._samples;
        },
        set: function (sampleCount) {
            if (this._samples === sampleCount) {
                return;
            }
            this._samples = sampleCount;
            this._buildPipeline();
        },
        enumerable: true,
        configurable: true
    });
    StandardRenderingPipeline.prototype._buildPipeline = function () {
        var _this = this;
        var ratio = this._ratio;
        var scene = this._scene;
        this._disposePostProcesses();
        if (this._cameras !== null) {
            this._scene.postProcessRenderPipelineManager.detachCamerasFromRenderPipeline(this._name, this._cameras);
            // get back cameras to be used to reattach pipeline
            this._cameras = this._camerasToBeAttached.slice();
        }
        this._reset();
        // Create pass post-process
        if (this._screenSpaceReflectionsEnabled) {
            this.screenSpaceReflectionPostProcess = new ScreenSpaceReflectionPostProcess("HDRPass", scene, ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, this._floatTextureType);
            this.screenSpaceReflectionPostProcess.onApplyObservable.add(function () {
                _this._currentDepthOfFieldSource = _this.screenSpaceReflectionPostProcess;
            });
            this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRScreenSpaceReflections", function () { return _this.screenSpaceReflectionPostProcess; }, true));
        }
        if (!this._basePostProcess) {
            this.originalPostProcess = new PostProcess("HDRPass", "standard", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define PASS_POST_PROCESS", this._floatTextureType);
        }
        else {
            this.originalPostProcess = this._basePostProcess;
        }
        this.originalPostProcess.autoClear = !this.screenSpaceReflectionPostProcess;
        this.originalPostProcess.onApplyObservable.add(function () {
            _this._currentDepthOfFieldSource = _this.originalPostProcess;
        });
        this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRPassPostProcess", function () { return _this.originalPostProcess; }, true));
        if (this._bloomEnabled) {
            // Create down sample X4 post-process
            this._createDownSampleX4PostProcess(scene, ratio / 4);
            // Create bright pass post-process
            this._createBrightPassPostProcess(scene, ratio / 4);
            // Create gaussian blur post-processes (down sampling blurs)
            this._createBlurPostProcesses(scene, ratio / 4, 1);
            // Create texture adder post-process
            this._createTextureAdderPostProcess(scene, ratio);
            // Create depth-of-field source post-process
            this.textureAdderFinalPostProcess = new PostProcess("HDRDepthOfFieldSource", "standard", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define PASS_POST_PROCESS", 0);
            this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRBaseDepthOfFieldSource", function () { return _this.textureAdderFinalPostProcess; }, true));
        }
        if (this._vlsEnabled) {
            // Create volumetric light
            this._createVolumetricLightPostProcess(scene, ratio);
            // Create volumetric light final post-process
            this.volumetricLightFinalPostProcess = new PostProcess("HDRVLSFinal", "standard", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define PASS_POST_PROCESS", 0);
            this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRVLSFinal", function () { return _this.volumetricLightFinalPostProcess; }, true));
        }
        if (this._lensFlareEnabled) {
            // Create lens flare post-process
            this._createLensFlarePostProcess(scene, ratio);
            // Create depth-of-field source post-process post lens-flare and disable it now
            this.lensFlareFinalPostProcess = new PostProcess("HDRPostLensFlareDepthOfFieldSource", "standard", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define PASS_POST_PROCESS", 0);
            this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRPostLensFlareDepthOfFieldSource", function () { return _this.lensFlareFinalPostProcess; }, true));
        }
        if (this._hdrEnabled) {
            // Create luminance
            this._createLuminancePostProcesses(scene, this._floatTextureType);
            // Create HDR
            this._createHdrPostProcess(scene, ratio);
            // Create depth-of-field source post-process post hdr and disable it now
            this.hdrFinalPostProcess = new PostProcess("HDRPostHDReDepthOfFieldSource", "standard", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define PASS_POST_PROCESS", 0);
            this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRPostHDReDepthOfFieldSource", function () { return _this.hdrFinalPostProcess; }, true));
        }
        if (this._depthOfFieldEnabled) {
            // Create gaussian blur used by depth-of-field
            this._createBlurPostProcesses(scene, ratio / 2, 3, "depthOfFieldBlurWidth");
            // Create depth-of-field post-process
            this._createDepthOfFieldPostProcess(scene, ratio);
        }
        if (this._motionBlurEnabled) {
            // Create motion blur post-process
            this._createMotionBlurPostProcess(scene, ratio);
        }
        if (this._fxaaEnabled) {
            // Create fxaa post-process
            this.fxaaPostProcess = new FxaaPostProcess("fxaa", 1.0, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, 0);
            this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRFxaa", function () { return _this.fxaaPostProcess; }, true));
        }
        if (this._cameras !== null) {
            this._scene.postProcessRenderPipelineManager.attachCamerasToRenderPipeline(this._name, this._cameras);
        }
        if (!this._enableMSAAOnFirstPostProcess(this._samples) && this._samples > 1) {
            Logger.Warn("MSAA failed to enable, MSAA is only supported in browsers that support webGL >= 2.0");
        }
    };
    // Down Sample X4 Post-Processs
    StandardRenderingPipeline.prototype._createDownSampleX4PostProcess = function (scene, ratio) {
        var _this = this;
        var downSampleX4Offsets = new Array(32);
        this.downSampleX4PostProcess = new PostProcess("HDRDownSampleX4", "standard", ["dsOffsets"], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define DOWN_SAMPLE_X4", this._floatTextureType);
        this.downSampleX4PostProcess.onApply = function (effect) {
            var id = 0;
            var width = _this.downSampleX4PostProcess.width;
            var height = _this.downSampleX4PostProcess.height;
            for (var i = -2; i < 2; i++) {
                for (var j = -2; j < 2; j++) {
                    downSampleX4Offsets[id] = (i + 0.5) * (1.0 / width);
                    downSampleX4Offsets[id + 1] = (j + 0.5) * (1.0 / height);
                    id += 2;
                }
            }
            effect.setArray2("dsOffsets", downSampleX4Offsets);
        };
        // Add to pipeline
        this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRDownSampleX4", function () { return _this.downSampleX4PostProcess; }, true));
    };
    // Brightpass Post-Process
    StandardRenderingPipeline.prototype._createBrightPassPostProcess = function (scene, ratio) {
        var _this = this;
        var brightOffsets = new Array(8);
        this.brightPassPostProcess = new PostProcess("HDRBrightPass", "standard", ["dsOffsets", "brightThreshold"], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define BRIGHT_PASS", this._floatTextureType);
        this.brightPassPostProcess.onApply = function (effect) {
            var sU = (1.0 / _this.brightPassPostProcess.width);
            var sV = (1.0 / _this.brightPassPostProcess.height);
            brightOffsets[0] = -0.5 * sU;
            brightOffsets[1] = 0.5 * sV;
            brightOffsets[2] = 0.5 * sU;
            brightOffsets[3] = 0.5 * sV;
            brightOffsets[4] = -0.5 * sU;
            brightOffsets[5] = -0.5 * sV;
            brightOffsets[6] = 0.5 * sU;
            brightOffsets[7] = -0.5 * sV;
            effect.setArray2("dsOffsets", brightOffsets);
            effect.setFloat("brightThreshold", _this.brightThreshold);
        };
        // Add to pipeline
        this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRBrightPass", function () { return _this.brightPassPostProcess; }, true));
    };
    // Create blur H&V post-processes
    StandardRenderingPipeline.prototype._createBlurPostProcesses = function (scene, ratio, indice, blurWidthKey) {
        var _this = this;
        if (blurWidthKey === void 0) { blurWidthKey = "blurWidth"; }
        var engine = scene.getEngine();
        var blurX = new BlurPostProcess("HDRBlurH" + "_" + indice, new Vector2(1, 0), this[blurWidthKey], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, this._floatTextureType);
        var blurY = new BlurPostProcess("HDRBlurV" + "_" + indice, new Vector2(0, 1), this[blurWidthKey], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, this._floatTextureType);
        blurX.onActivateObservable.add(function () {
            var dw = blurX.width / engine.getRenderWidth();
            blurX.kernel = _this[blurWidthKey] * dw;
        });
        blurY.onActivateObservable.add(function () {
            var dw = blurY.height / engine.getRenderHeight();
            blurY.kernel = _this.horizontalBlur ? 64 * dw : _this[blurWidthKey] * dw;
        });
        this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRBlurH" + indice, function () { return blurX; }, true));
        this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRBlurV" + indice, function () { return blurY; }, true));
        this.blurHPostProcesses.push(blurX);
        this.blurVPostProcesses.push(blurY);
    };
    // Create texture adder post-process
    StandardRenderingPipeline.prototype._createTextureAdderPostProcess = function (scene, ratio) {
        var _this = this;
        this.textureAdderPostProcess = new PostProcess("HDRTextureAdder", "standard", ["exposure"], ["otherSampler", "lensSampler"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define TEXTURE_ADDER", this._floatTextureType);
        this.textureAdderPostProcess.onApply = function (effect) {
            effect.setTextureFromPostProcess("otherSampler", _this._vlsEnabled ? _this._currentDepthOfFieldSource : _this.originalPostProcess);
            effect.setTexture("lensSampler", _this.lensTexture);
            effect.setFloat("exposure", _this._currentExposure);
            _this._currentDepthOfFieldSource = _this.textureAdderFinalPostProcess;
        };
        // Add to pipeline
        this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRTextureAdder", function () { return _this.textureAdderPostProcess; }, true));
    };
    StandardRenderingPipeline.prototype._createVolumetricLightPostProcess = function (scene, ratio) {
        var _this = this;
        var geometryRenderer = scene.enableGeometryBufferRenderer();
        geometryRenderer.enablePosition = true;
        var geometry = geometryRenderer.getGBuffer();
        // Base post-process
        this.volumetricLightPostProcess = new PostProcess("HDRVLS", "standard", ["shadowViewProjection", "cameraPosition", "sunDirection", "sunColor", "scatteringCoefficient", "scatteringPower", "depthValues"], ["shadowMapSampler", "positionSampler"], ratio / 8, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define VLS\n#define NB_STEPS " + this._volumetricLightStepsCount.toFixed(1));
        var depthValues = Vector2.Zero();
        this.volumetricLightPostProcess.onApply = function (effect) {
            if (_this.sourceLight && _this.sourceLight.getShadowGenerator() && _this._scene.activeCamera) {
                var generator = _this.sourceLight.getShadowGenerator();
                effect.setTexture("shadowMapSampler", generator.getShadowMap());
                effect.setTexture("positionSampler", geometry.textures[2]);
                effect.setColor3("sunColor", _this.sourceLight.diffuse);
                effect.setVector3("sunDirection", _this.sourceLight.getShadowDirection());
                effect.setVector3("cameraPosition", _this._scene.activeCamera.globalPosition);
                effect.setMatrix("shadowViewProjection", generator.getTransformMatrix());
                effect.setFloat("scatteringCoefficient", _this.volumetricLightCoefficient);
                effect.setFloat("scatteringPower", _this.volumetricLightPower);
                depthValues.x = _this.sourceLight.getDepthMinZ(_this._scene.activeCamera);
                depthValues.y = _this.sourceLight.getDepthMaxZ(_this._scene.activeCamera);
                effect.setVector2("depthValues", depthValues);
            }
        };
        this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRVLS", function () { return _this.volumetricLightPostProcess; }, true));
        // Smooth
        this._createBlurPostProcesses(scene, ratio / 4, 0, "volumetricLightBlurScale");
        // Merge
        this.volumetricLightMergePostProces = new PostProcess("HDRVLSMerge", "standard", [], ["originalSampler"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define VLSMERGE");
        this.volumetricLightMergePostProces.onApply = function (effect) {
            effect.setTextureFromPostProcess("originalSampler", _this._bloomEnabled ? _this.textureAdderFinalPostProcess : _this.originalPostProcess);
            _this._currentDepthOfFieldSource = _this.volumetricLightFinalPostProcess;
        };
        this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRVLSMerge", function () { return _this.volumetricLightMergePostProces; }, true));
    };
    // Create luminance
    StandardRenderingPipeline.prototype._createLuminancePostProcesses = function (scene, textureType) {
        var _this = this;
        // Create luminance
        var size = Math.pow(3, StandardRenderingPipeline.LuminanceSteps);
        this.luminancePostProcess = new PostProcess("HDRLuminance", "standard", ["lumOffsets"], [], { width: size, height: size }, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define LUMINANCE", textureType);
        var offsets = [];
        this.luminancePostProcess.onApply = function (effect) {
            var sU = (1.0 / _this.luminancePostProcess.width);
            var sV = (1.0 / _this.luminancePostProcess.height);
            offsets[0] = -0.5 * sU;
            offsets[1] = 0.5 * sV;
            offsets[2] = 0.5 * sU;
            offsets[3] = 0.5 * sV;
            offsets[4] = -0.5 * sU;
            offsets[5] = -0.5 * sV;
            offsets[6] = 0.5 * sU;
            offsets[7] = -0.5 * sV;
            effect.setArray2("lumOffsets", offsets);
        };
        // Add to pipeline
        this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRLuminance", function () { return _this.luminancePostProcess; }, true));
        // Create down sample luminance
        for (var i = StandardRenderingPipeline.LuminanceSteps - 1; i >= 0; i--) {
            var size = Math.pow(3, i);
            var defines = "#define LUMINANCE_DOWN_SAMPLE\n";
            if (i === 0) {
                defines += "#define FINAL_DOWN_SAMPLER";
            }
            var postProcess = new PostProcess("HDRLuminanceDownSample" + i, "standard", ["dsOffsets", "halfDestPixelSize"], [], { width: size, height: size }, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, defines, textureType);
            this.luminanceDownSamplePostProcesses.push(postProcess);
        }
        // Create callbacks and add effects
        var lastLuminance = this.luminancePostProcess;
        this.luminanceDownSamplePostProcesses.forEach(function (pp, index) {
            var downSampleOffsets = new Array(18);
            pp.onApply = function (effect) {
                if (!lastLuminance) {
                    return;
                }
                var id = 0;
                for (var x = -1; x < 2; x++) {
                    for (var y = -1; y < 2; y++) {
                        downSampleOffsets[id] = x / lastLuminance.width;
                        downSampleOffsets[id + 1] = y / lastLuminance.height;
                        id += 2;
                    }
                }
                effect.setArray2("dsOffsets", downSampleOffsets);
                effect.setFloat("halfDestPixelSize", 0.5 / lastLuminance.width);
                if (index === _this.luminanceDownSamplePostProcesses.length - 1) {
                    lastLuminance = _this.luminancePostProcess;
                }
                else {
                    lastLuminance = pp;
                }
            };
            if (index === _this.luminanceDownSamplePostProcesses.length - 1) {
                pp.onAfterRender = function () {
                    var pixel = scene.getEngine().readPixels(0, 0, 1, 1);
                    var bit_shift = new Vector4(1.0 / (255.0 * 255.0 * 255.0), 1.0 / (255.0 * 255.0), 1.0 / 255.0, 1.0);
                    _this._hdrCurrentLuminance = (pixel[0] * bit_shift.x + pixel[1] * bit_shift.y + pixel[2] * bit_shift.z + pixel[3] * bit_shift.w) / 100.0;
                };
            }
            _this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRLuminanceDownSample" + index, function () { return pp; }, true));
        });
    };
    // Create HDR post-process
    StandardRenderingPipeline.prototype._createHdrPostProcess = function (scene, ratio) {
        var _this = this;
        var defines = ["#define HDR"];
        if (this._hdrAutoExposure) {
            defines.push("#define AUTO_EXPOSURE");
        }
        this.hdrPostProcess = new PostProcess("HDR", "standard", ["averageLuminance"], ["textureAdderSampler"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, defines.join("\n"), 0);
        var outputLiminance = 1;
        var time = 0;
        var lastTime = 0;
        this.hdrPostProcess.onApply = function (effect) {
            effect.setTextureFromPostProcess("textureAdderSampler", _this._currentDepthOfFieldSource);
            time += scene.getEngine().getDeltaTime();
            if (outputLiminance < 0) {
                outputLiminance = _this._hdrCurrentLuminance;
            }
            else {
                var dt = (lastTime - time) / 1000.0;
                if (_this._hdrCurrentLuminance < outputLiminance + _this.hdrDecreaseRate * dt) {
                    outputLiminance += _this.hdrDecreaseRate * dt;
                }
                else if (_this._hdrCurrentLuminance > outputLiminance - _this.hdrIncreaseRate * dt) {
                    outputLiminance -= _this.hdrIncreaseRate * dt;
                }
                else {
                    outputLiminance = _this._hdrCurrentLuminance;
                }
            }
            if (_this.hdrAutoExposure) {
                _this._currentExposure = _this._fixedExposure / outputLiminance;
            }
            else {
                outputLiminance = Scalar.Clamp(outputLiminance, _this.hdrMinimumLuminance, 1e20);
                effect.setFloat("averageLuminance", outputLiminance);
            }
            lastTime = time;
            _this._currentDepthOfFieldSource = _this.hdrFinalPostProcess;
        };
        this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDR", function () { return _this.hdrPostProcess; }, true));
    };
    // Create lens flare post-process
    StandardRenderingPipeline.prototype._createLensFlarePostProcess = function (scene, ratio) {
        var _this = this;
        this.lensFlarePostProcess = new PostProcess("HDRLensFlare", "standard", ["strength", "ghostDispersal", "haloWidth", "resolution", "distortionStrength"], ["lensColorSampler"], ratio / 2, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define LENS_FLARE", 0);
        this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRLensFlare", function () { return _this.lensFlarePostProcess; }, true));
        this._createBlurPostProcesses(scene, ratio / 4, 2, "lensFlareBlurWidth");
        this.lensFlareComposePostProcess = new PostProcess("HDRLensFlareCompose", "standard", ["lensStarMatrix"], ["otherSampler", "lensDirtSampler", "lensStarSampler"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define LENS_FLARE_COMPOSE", 0);
        this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRLensFlareCompose", function () { return _this.lensFlareComposePostProcess; }, true));
        var resolution = new Vector2(0, 0);
        // Lens flare
        this.lensFlarePostProcess.onApply = function (effect) {
            effect.setTextureFromPostProcess("textureSampler", _this._bloomEnabled ? _this.blurHPostProcesses[0] : _this.originalPostProcess);
            effect.setTexture("lensColorSampler", _this.lensColorTexture);
            effect.setFloat("strength", _this.lensFlareStrength);
            effect.setFloat("ghostDispersal", _this.lensFlareGhostDispersal);
            effect.setFloat("haloWidth", _this.lensFlareHaloWidth);
            // Shift
            resolution.x = _this.lensFlarePostProcess.width;
            resolution.y = _this.lensFlarePostProcess.height;
            effect.setVector2("resolution", resolution);
            effect.setFloat("distortionStrength", _this.lensFlareDistortionStrength);
        };
        // Compose
        var scaleBias1 = Matrix.FromValues(2.0, 0.0, -1.0, 0.0, 0.0, 2.0, -1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0);
        var scaleBias2 = Matrix.FromValues(0.5, 0.0, 0.5, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0);
        this.lensFlareComposePostProcess.onApply = function (effect) {
            if (!_this._scene.activeCamera) {
                return;
            }
            effect.setTextureFromPostProcess("otherSampler", _this.lensFlarePostProcess);
            effect.setTexture("lensDirtSampler", _this.lensFlareDirtTexture);
            effect.setTexture("lensStarSampler", _this.lensStarTexture);
            // Lens start rotation matrix
            var camerax = _this._scene.activeCamera.getViewMatrix().getRow(0);
            var cameraz = _this._scene.activeCamera.getViewMatrix().getRow(2);
            var camRot = Vector3.Dot(camerax.toVector3(), new Vector3(1.0, 0.0, 0.0)) + Vector3.Dot(cameraz.toVector3(), new Vector3(0.0, 0.0, 1.0));
            camRot *= 4.0;
            var starRotation = Matrix.FromValues(Math.cos(camRot) * 0.5, -Math.sin(camRot), 0.0, 0.0, Math.sin(camRot), Math.cos(camRot) * 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0);
            var lensStarMatrix = scaleBias2.multiply(starRotation).multiply(scaleBias1);
            effect.setMatrix("lensStarMatrix", lensStarMatrix);
            _this._currentDepthOfFieldSource = _this.lensFlareFinalPostProcess;
        };
    };
    // Create depth-of-field post-process
    StandardRenderingPipeline.prototype._createDepthOfFieldPostProcess = function (scene, ratio) {
        var _this = this;
        this.depthOfFieldPostProcess = new PostProcess("HDRDepthOfField", "standard", ["distance"], ["otherSampler", "depthSampler"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define DEPTH_OF_FIELD", 0);
        this.depthOfFieldPostProcess.onApply = function (effect) {
            effect.setTextureFromPostProcess("otherSampler", _this._currentDepthOfFieldSource);
            effect.setTexture("depthSampler", _this._getDepthTexture());
            effect.setFloat("distance", _this.depthOfFieldDistance);
        };
        // Add to pipeline
        this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRDepthOfField", function () { return _this.depthOfFieldPostProcess; }, true));
    };
    // Create motion blur post-process
    StandardRenderingPipeline.prototype._createMotionBlurPostProcess = function (scene, ratio) {
        var _this = this;
        if (this._isObjectBasedMotionBlur) {
            var mb = new MotionBlurPostProcess("HDRMotionBlur", scene, ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, 0);
            mb.motionStrength = this.motionStrength;
            mb.motionBlurSamples = this.motionBlurSamples;
            this.motionBlurPostProcess = mb;
        }
        else {
            this.motionBlurPostProcess = new PostProcess("HDRMotionBlur", "standard", ["inverseViewProjection", "prevViewProjection", "screenSize", "motionScale", "motionStrength"], ["depthSampler"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, "#define MOTION_BLUR\n#define MAX_MOTION_SAMPLES " + this.motionBlurSamples.toFixed(1), 0);
            var motionScale = 0;
            var prevViewProjection = Matrix.Identity();
            var invViewProjection = Matrix.Identity();
            var viewProjection = Matrix.Identity();
            var screenSize = Vector2.Zero();
            this.motionBlurPostProcess.onApply = function (effect) {
                viewProjection = scene.getProjectionMatrix().multiply(scene.getViewMatrix());
                viewProjection.invertToRef(invViewProjection);
                effect.setMatrix("inverseViewProjection", invViewProjection);
                effect.setMatrix("prevViewProjection", prevViewProjection);
                prevViewProjection = viewProjection;
                screenSize.x = _this.motionBlurPostProcess.width;
                screenSize.y = _this.motionBlurPostProcess.height;
                effect.setVector2("screenSize", screenSize);
                motionScale = scene.getEngine().getFps() / 60.0;
                effect.setFloat("motionScale", motionScale);
                effect.setFloat("motionStrength", _this.motionStrength);
                effect.setTexture("depthSampler", _this._getDepthTexture());
            };
        }
        this.addEffect(new PostProcessRenderEffect(scene.getEngine(), "HDRMotionBlur", function () { return _this.motionBlurPostProcess; }, true));
    };
    StandardRenderingPipeline.prototype._getDepthTexture = function () {
        if (this._scene.getEngine().getCaps().drawBuffersExtension) {
            var renderer = this._scene.enableGeometryBufferRenderer();
            return renderer.getGBuffer().textures[0];
        }
        return this._scene.enableDepthRenderer().getDepthMap();
    };
    StandardRenderingPipeline.prototype._disposePostProcesses = function () {
        for (var i = 0; i < this._cameras.length; i++) {
            var camera = this._cameras[i];
            if (this.originalPostProcess) {
                this.originalPostProcess.dispose(camera);
            }
            if (this.screenSpaceReflectionPostProcess) {
                this.screenSpaceReflectionPostProcess.dispose(camera);
            }
            if (this.downSampleX4PostProcess) {
                this.downSampleX4PostProcess.dispose(camera);
            }
            if (this.brightPassPostProcess) {
                this.brightPassPostProcess.dispose(camera);
            }
            if (this.textureAdderPostProcess) {
                this.textureAdderPostProcess.dispose(camera);
            }
            if (this.volumetricLightPostProcess) {
                this.volumetricLightPostProcess.dispose(camera);
            }
            if (this.volumetricLightSmoothXPostProcess) {
                this.volumetricLightSmoothXPostProcess.dispose(camera);
            }
            if (this.volumetricLightSmoothYPostProcess) {
                this.volumetricLightSmoothYPostProcess.dispose(camera);
            }
            if (this.volumetricLightMergePostProces) {
                this.volumetricLightMergePostProces.dispose(camera);
            }
            if (this.volumetricLightFinalPostProcess) {
                this.volumetricLightFinalPostProcess.dispose(camera);
            }
            if (this.lensFlarePostProcess) {
                this.lensFlarePostProcess.dispose(camera);
            }
            if (this.lensFlareComposePostProcess) {
                this.lensFlareComposePostProcess.dispose(camera);
            }
            for (var j = 0; j < this.luminanceDownSamplePostProcesses.length; j++) {
                this.luminanceDownSamplePostProcesses[j].dispose(camera);
            }
            if (this.luminancePostProcess) {
                this.luminancePostProcess.dispose(camera);
            }
            if (this.hdrPostProcess) {
                this.hdrPostProcess.dispose(camera);
            }
            if (this.hdrFinalPostProcess) {
                this.hdrFinalPostProcess.dispose(camera);
            }
            if (this.depthOfFieldPostProcess) {
                this.depthOfFieldPostProcess.dispose(camera);
            }
            if (this.motionBlurPostProcess) {
                this.motionBlurPostProcess.dispose(camera);
            }
            if (this.fxaaPostProcess) {
                this.fxaaPostProcess.dispose(camera);
            }
            for (var j = 0; j < this.blurHPostProcesses.length; j++) {
                this.blurHPostProcesses[j].dispose(camera);
            }
            for (var j = 0; j < this.blurVPostProcesses.length; j++) {
                this.blurVPostProcesses[j].dispose(camera);
            }
        }
        this.originalPostProcess = null;
        this.downSampleX4PostProcess = null;
        this.brightPassPostProcess = null;
        this.textureAdderPostProcess = null;
        this.textureAdderFinalPostProcess = null;
        this.volumetricLightPostProcess = null;
        this.volumetricLightSmoothXPostProcess = null;
        this.volumetricLightSmoothYPostProcess = null;
        this.volumetricLightMergePostProces = null;
        this.volumetricLightFinalPostProcess = null;
        this.lensFlarePostProcess = null;
        this.lensFlareComposePostProcess = null;
        this.luminancePostProcess = null;
        this.hdrPostProcess = null;
        this.hdrFinalPostProcess = null;
        this.depthOfFieldPostProcess = null;
        this.motionBlurPostProcess = null;
        this.fxaaPostProcess = null;
        this.screenSpaceReflectionPostProcess = null;
        this.luminanceDownSamplePostProcesses = [];
        this.blurHPostProcesses = [];
        this.blurVPostProcesses = [];
    };
    /**
     * Dispose of the pipeline and stop all post processes
     */
    StandardRenderingPipeline.prototype.dispose = function () {
        this._disposePostProcesses();
        this._scene.postProcessRenderPipelineManager.detachCamerasFromRenderPipeline(this._name, this._cameras);
        _super.prototype.dispose.call(this);
    };
    /**
     * Serialize the rendering pipeline (Used when exporting)
     * @returns the serialized object
     */
    StandardRenderingPipeline.prototype.serialize = function () {
        var serializationObject = SerializationHelper.Serialize(this);
        if (this.sourceLight) {
            serializationObject.sourceLightId = this.sourceLight.id;
        }
        if (this.screenSpaceReflectionPostProcess) {
            serializationObject.screenSpaceReflectionPostProcess = SerializationHelper.Serialize(this.screenSpaceReflectionPostProcess);
        }
        serializationObject.customType = "StandardRenderingPipeline";
        return serializationObject;
    };
    /**
     * Parse the serialized pipeline
     * @param source Source pipeline.
     * @param scene The scene to load the pipeline to.
     * @param rootUrl The URL of the serialized pipeline.
     * @returns An instantiated pipeline from the serialized object.
     */
    StandardRenderingPipeline.Parse = function (source, scene, rootUrl) {
        var p = SerializationHelper.Parse(function () { return new StandardRenderingPipeline(source._name, scene, source._ratio); }, source, scene, rootUrl);
        if (source.sourceLightId) {
            p.sourceLight = scene.getLightByID(source.sourceLightId);
        }
        if (source.screenSpaceReflectionPostProcess) {
            SerializationHelper.Parse(function () { return p.screenSpaceReflectionPostProcess; }, source.screenSpaceReflectionPostProcess, scene, rootUrl);
        }
        return p;
    };
    /**
     * Luminance steps
     */
    StandardRenderingPipeline.LuminanceSteps = 6;
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "brightThreshold", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "blurWidth", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "horizontalBlur", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "exposure", null);
    __decorate([
        serializeAsTexture("lensTexture")
    ], StandardRenderingPipeline.prototype, "lensTexture", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "volumetricLightCoefficient", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "volumetricLightPower", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "volumetricLightBlurScale", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "hdrMinimumLuminance", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "hdrDecreaseRate", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "hdrIncreaseRate", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "hdrAutoExposure", null);
    __decorate([
        serializeAsTexture("lensColorTexture")
    ], StandardRenderingPipeline.prototype, "lensColorTexture", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "lensFlareStrength", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "lensFlareGhostDispersal", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "lensFlareHaloWidth", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "lensFlareDistortionStrength", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "lensFlareBlurWidth", void 0);
    __decorate([
        serializeAsTexture("lensStarTexture")
    ], StandardRenderingPipeline.prototype, "lensStarTexture", void 0);
    __decorate([
        serializeAsTexture("lensFlareDirtTexture")
    ], StandardRenderingPipeline.prototype, "lensFlareDirtTexture", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "depthOfFieldDistance", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "depthOfFieldBlurWidth", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "motionStrength", null);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "objectBasedMotionBlur", null);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "_ratio", void 0);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "BloomEnabled", null);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "DepthOfFieldEnabled", null);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "LensFlareEnabled", null);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "HDREnabled", null);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "VLSEnabled", null);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "MotionBlurEnabled", null);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "fxaaEnabled", null);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "screenSpaceReflectionsEnabled", null);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "volumetricLightStepsCount", null);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "motionBlurSamples", null);
    __decorate([
        serialize()
    ], StandardRenderingPipeline.prototype, "samples", null);
    return StandardRenderingPipeline;
}(PostProcessRenderPipeline));
export { StandardRenderingPipeline };
_TypeStore.RegisteredTypes["BABYLON.StandardRenderingPipeline"] = StandardRenderingPipeline;
//# sourceMappingURL=standardRenderingPipeline.js.map